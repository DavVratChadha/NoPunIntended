{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fweXob2vCD9K",
        "outputId": "dd719a51-7d5b-499b-c941-39222cbd510c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers #installing because we want to use pre_trained models, both from huggingface and our own models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "import re\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, DebertaTokenizer, DebertaForSequenceClassification\n",
        "from transformers import AutoModel\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import NAdam\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import math"
      ],
      "metadata": {
        "id": "rv1SyyaUNRL2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl2uItDiIms3",
        "outputId": "48c2ffd8-bae7-457b-a3d6-05d443ea296c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-14 01:48:29.206465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-lg==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning) #ignoring UserWarning from colab because I know what I am doing here\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "SAbVXnoyNTaU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "base_dir = '/content/drive/My Drive/ESC324projectdrive/dav/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg5YC1OnNVgl",
        "outputId": "d9756ba6-6df6-4536-a3db-c044a263bd22"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data"
      ],
      "metadata": {
        "id": "BA6yFuhpNXPL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
        "nlp.add_pipe('sentencizer')\n",
        "\n",
        "rel_freq = load_pickle(base_dir + 'tag_dict.pickle')\n",
        "print(rel_freq)\n",
        "\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "deberta_tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
        "\n",
        "\n",
        "\n",
        "roberta_model = transformers.RobertaForSequenceClassification.from_pretrained(base_dir + 'trained_roberta_model')\n",
        "deberta_model = transformers.DebertaForSequenceClassification.from_pretrained(base_dir + 'trained_deberta_model')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFx1XNtxNaih",
        "outputId": "abe0fca9-0818-4352-c78c-792adf56d4ce"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0.0003436426116838488, \"''\": 0.0003436426116838488, ',': 0.0003436426116838488, '-LRB-': 0.0003436426116838488, '-RRB-': 0.0003436426116838488, '.': 0.0003436426116838488, ':': 0.0003436426116838488, 'CC': 0.0003436426116838488, 'CD': 0.0010309278350515464, 'DT': 0.0003436426116838488, 'EX': 0.0003436426116838488, 'FW': 0.0006872852233676976, 'HYPH': 0.0003436426116838488, 'IN': 0.0024054982817869417, 'JJ': 0.11134020618556702, 'JJR': 0.0013745704467353953, 'JJS': 0.0013745704467353953, 'LS': 0.0003436426116838488, 'MD': 0.0013745704467353953, 'NFP': 0.0003436426116838488, 'NN': 0.3518900343642612, 'NNP': 0.07835051546391752, 'NNPS': 0.0013745704467353953, 'NNS': 0.09725085910652921, 'PDT': 0.0003436426116838488, 'POS': 0.0003436426116838488, 'PRP': 0.0006872852233676976, 'PRP$': 0.0003436426116838488, 'RB': 0.06632302405498282, 'RBR': 0.0006872852233676976, 'RBS': 0.0003436426116838488, 'RP': 0.001718213058419244, 'TO': 0.0003436426116838488, 'UH': 0.002061855670103093, 'VB': 0.07835051546391752, 'VBD': 0.05979381443298969, 'VBG': 0.03573883161512027, 'VBN': 0.05910652920962199, 'VBP': 0.032989690721649485, 'VBZ': 0.005498281786941581, 'WDT': 0.0003436426116838488, 'WP': 0.0003436426116838488, 'WP$': 0.0003436426116838488, 'WRB': 0.0003436426116838488, 'XX': 0.0003436426116838488, '_SP': 0.0003436426116838488, '``': 0.0003436426116838488}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_processor(sentence):\n",
        "  \"\"\"Helper function to process the input sentence by fixing punctuation and POS tagging it\"\"\"\n",
        "  unprocessed_sentence = []\n",
        "  processed_sentence = []\n",
        "\n",
        "  #remove extra spaces using rejex\n",
        "  sentence = re.sub(' +', ' ', sentence)\n",
        "  #replace ' m with 'm\n",
        "  sentence = sentence.replace(\"' m\", \"'m\")\n",
        "  #replace ' s with 's\n",
        "  sentence = sentence.replace(\"' s\", \"'s\")\n",
        "  #replace ' ve with 've\n",
        "  sentence = sentence.replace(\"' ve\", \"'ve\")\n",
        "  #replace ' re with 're\n",
        "  sentence = sentence.replace(\"' re\", \"'re\")        \n",
        "  #replace ' d with 'd\n",
        "  sentence = sentence.replace(\"' d\", \"'d\")\n",
        "  #replace ' ll with 'll\n",
        "  sentence = sentence.replace(\"' ll\", \"'ll\")\n",
        "  #replace ' t with 't\n",
        "  sentence = sentence.replace(\"' t\", \"'t\")\n",
        "  #replace '' with \"\n",
        "  sentence = sentence.replace(\"''\", \"\\\"\")\n",
        "  \n",
        "  #remove new line character at the end of the sentence\n",
        "  sentence = sentence.strip()\n",
        "  sentence = nlp(sentence)\n",
        "  for sent in sentence.sents:\n",
        "      for token in sent:\n",
        "          #Write \"/POS\" after each token.\n",
        "          #Split tokens with spaces.\n",
        "          token.lemma_ = token.lemma_.lower()\n",
        "          #replace pun with its lemma\n",
        "          processed_sentence.append(token.lemma_ + \"/\" + token.tag_)\n",
        "          unprocessed_sentence.append(token.text)\n",
        "  return [processed_sentence, unprocessed_sentence]"
      ],
      "metadata": {
        "id": "ByE73V8rH7id"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roberta_predictor(input_list, print_output):\n",
        "  pos_sentence = input_list[0]\n",
        "  sentence = input_list[1]\n",
        "  max_len = 79 #dont change\n",
        "  #creating an array of heuristic based on rel_freq mapping for each tag in pos_sentence\n",
        "  rel_freq_heuristic = [0]\n",
        "  for word in pos_sentence:\n",
        "    rel_freq_heuristic.append(rel_freq.get(word.split(\"/\")[1], 0))\n",
        "  rel_freq_heuristic += [0]*(max_len - len(rel_freq_heuristic))\n",
        "  rel_freq_heuristic = torch.tensor(rel_freq_heuristic)\n",
        "\n",
        "  k_means_output = []\n",
        "\n",
        "  encoded_data = roberta_tokenizer.encode_plus(\n",
        "          sentence,\n",
        "          add_special_tokens=True,\n",
        "          max_length = max_len, #we are padding all sentences to a max_len elements (words + punction)\n",
        "          pad_to_max_length = True,\n",
        "          return_attention_mask = False,\n",
        "          return_tensors='pt',\n",
        "          truncation = True\n",
        "      )\n",
        "\n",
        "  temp = np.array(encoded_data['input_ids'][0].tolist().copy())\n",
        "  temp = temp[temp != temp[-1]] #remove padding\n",
        "\n",
        "  multiplier = 0.5 #you can change this value to affect how the test model works. This is a hyperparameter which changes the max number of clusters for kmeans\n",
        "  #mutliplier has been set to 0.5 because RoBERTa was fine-tuned by us with this value\n",
        "  num_clusters = max(math.ceil(len(temp)*multiplier), min(5, len(sentence)))\n",
        "\n",
        "  kmeans = KMeans(n_clusters = num_clusters, n_init = 10)\n",
        "  kmeans.fit(temp.reshape(-1, 1))\n",
        "  att_labels = np.array(kmeans.labels_)\n",
        "  k_means_output.append(kmeans.labels_)\n",
        "\n",
        "  unique, count = (np.unique(att_labels, return_counts = True))\n",
        "\n",
        "  idx = np.argsort(count)\n",
        "  count = count[idx]\n",
        "  unique = unique[idx]\n",
        "\n",
        "  first_mode = unique[-1]\n",
        "  attention_mask = torch.tensor([0] * max_len)\n",
        "  indices = np.where(att_labels == first_mode)\n",
        "  attention_mask[indices] = 1\n",
        "\n",
        "  \n",
        "  lone_word = unique[np.where(count == 1)]\n",
        "  lone_word_ind = np.where(np.isin(att_labels, lone_word))[0]\n",
        "  attention_mask[lone_word_ind] = 1\n",
        "\n",
        "  if len(unique) > 1:\n",
        "    second_lowest_chosen = unique[1]\n",
        "    indices2 = np.where(att_labels == second_lowest_chosen)\n",
        "    attention_mask[indices2] = 1\n",
        "                                              \n",
        "  input_id = torch.stack([encoded_data['input_ids'][0]], dim = 0)\n",
        "  attention_mask = torch.stack([attention_mask], dim = 0)\n",
        "\n",
        "  #use fine-tuned model\n",
        "  model_output = roberta_model(input_id, attention_mask = attention_mask)\n",
        "  model_output = torch.softmax(model_output[\"logits\"].detach(), dim = 1) * rel_freq_heuristic\n",
        "  model_pred = torch.argmax(model_output, dim = 1)\n",
        "  model_confidence = torch.max(model_output, dim = 1)\n",
        "  #updating some values\n",
        "  if model_pred == 0:\n",
        "    model_pred = 1\n",
        "  pred_pun = sentence[model_pred.item() - 1]\n",
        "  model_confidence = model_confidence[0][0].item()*100\n",
        "  return pred_pun, model_confidence"
      ],
      "metadata": {
        "id": "ugLY3rzxWv8F"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deberta_predictor(input_list, print_output):\n",
        "  pos_sentence = input_list[0]\n",
        "  sentence = input_list[1]\n",
        "  max_len = 79 #dont change\n",
        "  #creating an array of heuristic based on rel_freq mapping for each tag in pos_sentence\n",
        "  rel_freq_heuristic = [0]\n",
        "  for word in pos_sentence:\n",
        "    rel_freq_heuristic.append(rel_freq.get(word.split(\"/\")[1], 0))\n",
        "  rel_freq_heuristic += [0]*(max_len - len(rel_freq_heuristic))\n",
        "  rel_freq_heuristic = torch.tensor(rel_freq_heuristic)\n",
        "\n",
        "  k_means_output = []\n",
        "\n",
        "  encoded_data = deberta_tokenizer.encode_plus(\n",
        "          sentence,\n",
        "          add_special_tokens=True,\n",
        "          max_length = max_len, #we are padding all sentences to a max_len elements (words + punction)\n",
        "          pad_to_max_length = True,\n",
        "          return_attention_mask = False,\n",
        "          return_tensors='pt',\n",
        "          truncation = True\n",
        "      )\n",
        "\n",
        "  temp = np.array(encoded_data['input_ids'][0].tolist().copy())\n",
        "  temp = temp[temp != temp[-1]] #remove padding\n",
        "\n",
        "  multiplier = 1 #you can change this value to affect how the test model works. This is a hyperparameter which changes the max number of clusters for kmeans\n",
        "  #mutliplier has been set to 1 because deberta was fine-tuned by us with this value\n",
        "  num_clusters = max(math.ceil(len(temp)*multiplier), min(5, len(sentence)))\n",
        "\n",
        "  kmeans = KMeans(n_clusters = num_clusters, n_init = 10)\n",
        "  kmeans.fit(temp.reshape(-1, 1))\n",
        "  att_labels = np.array(kmeans.labels_)\n",
        "  k_means_output.append(kmeans.labels_)\n",
        "\n",
        "  unique, count = (np.unique(att_labels, return_counts = True))\n",
        "\n",
        "  idx = np.argsort(count)\n",
        "  count = count[idx]\n",
        "  unique = unique[idx]\n",
        "\n",
        "  first_mode = unique[-1]\n",
        "  attention_mask = torch.tensor([0] * max_len)\n",
        "  indices = np.where(att_labels == first_mode)\n",
        "  attention_mask[indices] = 1\n",
        "  \n",
        "  lone_word = unique[np.where(count == 1)]\n",
        "  lone_word_ind = np.where(np.isin(att_labels, lone_word))[0]\n",
        "  attention_mask[lone_word_ind] = 1\n",
        "\n",
        "  if len(unique) > 1:\n",
        "    second_lowest_chosen = unique[1]\n",
        "    indices2 = np.where(att_labels == second_lowest_chosen)\n",
        "    attention_mask[indices2] = 1\n",
        "                                              \n",
        "  input_id = torch.stack([encoded_data['input_ids'][0]], dim = 0)\n",
        "  attention_mask = torch.stack([attention_mask], dim = 0)\n",
        "\n",
        "  #use fine-tuned model\n",
        "  model_output = deberta_model(input_id, attention_mask = attention_mask)\n",
        "  model_output = torch.softmax(model_output[\"logits\"].detach(), dim = 1) * rel_freq_heuristic\n",
        "  model_pred = torch.argmax(model_output, dim = 1)\n",
        "  model_confidence = torch.max(model_output, dim = 1)\n",
        "  #updating some values\n",
        "  if model_pred == 0:\n",
        "    model_pred = 1\n",
        "  pred_pun = sentence[model_pred.item() - 1]\n",
        "  model_confidence = model_confidence[0][0].item()*100\n",
        "  return pred_pun, model_confidence"
      ],
      "metadata": {
        "id": "ZLSCRJhJopXn"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PunPal(input_sentence = \"\", model_name = \"ensemble\", print_output = True):\n",
        "  \"\"\"This function acts as an API to test the models trained by us on any input sentence.\n",
        "  Input:\n",
        "      input_sentence: <your sentence>\n",
        "      model_name: roberta / deberta / ensemble\n",
        "      print_output (optional): True / False\n",
        "  Output:\n",
        "      model_pred: Predicted pun word\n",
        "      model_confidence: Confidence rate of a word being a pun\n",
        "  \"\"\"\n",
        "  if len(input_sentence) == 0:\n",
        "    print(\"Invalid sentence\")\n",
        "    return None, None\n",
        "\n",
        "  #POS tagging\n",
        "  output_list = sentence_processor(input_sentence)\n",
        "  \n",
        "  roberta_pred, roberta_conf = roberta_predictor(output_list, print_output)\n",
        "  deberta_pred, deberta_conf = deberta_predictor(output_list, print_output)\n",
        "  \n",
        "  if print_output:\n",
        "    print(\"RoBERTa predicts that the Pun word is '\", roberta_pred, \"' with confidence = \", roberta_conf, \"%\")\n",
        "    print(\"DeBERTa predicts that the Pun word is '\", deberta_pred, \"' with confidence = \", deberta_conf, \"%\")\n",
        "  \n",
        "  if model_name == \"roberta\":\n",
        "    return roberta_pred, roberta_conf\n",
        "\n",
        "  elif model_name == \"deberta\":\n",
        "    return deberta_pred, deberta_conf\n",
        "  \n",
        "  elif model_name == \"ensemble\":\n",
        "    if roberta_conf > deberta_conf:\n",
        "      return roberta_pred, roberta_conf\n",
        "    else:\n",
        "      return deberta_pred, deberta_conf\n",
        "  else:\n",
        "    print(\"Invalid Model name\")\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "uUrZcB90N1pg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = roberta / deberta / ensemble\n",
        "#input = <your sentence>\n",
        "#print_output (optional) = True / False\n",
        "\n",
        "model = \"roberta\"\n",
        "input = \"When the glassblower inhaled he got a pane in the stomach.\"\n",
        "pred, conf = PunPal(input_sentence = input, model_name = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1U2bnR6ajMw",
        "outputId": "71de2f70-1a6d-4338-e7d4-63826618840f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoBERTa predicts that the Pun word is ' pane ' with confidence =  35.05114158813896 %\n",
            "DeBERTa predicts that the Pun word is ' pane ' with confidence =  34.76151194359429 %\n"
          ]
        }
      ]
    }
  ]
}