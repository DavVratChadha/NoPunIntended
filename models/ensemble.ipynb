{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers #installing because we want to use pre_trained models, both from huggingface and our own models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlBIEwV_GjUw",
        "outputId": "2bd0f4c3-5572-45bc-fdd5-0fb03ec4d07a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hnWtwGmOLzsW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import DebertaForSequenceClassification, RobertaForSequenceClassification\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_dir = '/content/drive/My Drive/ESC324projectdrive/dav/'"
      ],
      "metadata": {
        "id": "I2pYKVkhC-JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8c92dd-6c17-4f5d-e67a-92764935f4cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S1fTP0l0LzsZ"
      },
      "outputs": [],
      "source": [
        "#function to load pickle files\n",
        "def load_pickle(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "#loading the pickle files\n",
        "(train_dataloader_roberta, val_dataloader_roberta, test_dataloader_roberta) = load_pickle(base_dir + 'dataloaders_roberta_final.pickle')\n",
        "(train_dataloader_deberta, val_dataloader_deberta, test_dataloader_deberta) = load_pickle(base_dir + 'dataloaders_deberta_final.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYWvGJBLzsa",
        "outputId": "f338a284-d903-461a-b4eb-a65f4b222ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Cuda\n"
          ]
        }
      ],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "roberta_model = RobertaForSequenceClassification.from_pretrained(base_dir + 'trained_roberta_model')\n",
        "deberta_model = DebertaForSequenceClassification.from_pretrained(base_dir + 'trained_deberta_model') \n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "deberta_model.to(device)\n",
        "roberta_model.to(device)\n",
        "print([\"Using CPU\", \"Using Cuda\"][int(torch.cuda.is_available())])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate accuracy of the model for a given batch of data\n",
        "def accuracy(roberta_model_output, deberta_model_output, ground_truth_labels, rel_freq_heuristic):\n",
        "  roberta_model_output = torch.softmax(roberta_model_output, dim = 1) * rel_freq_heuristic.cpu()\n",
        "  roberta_model_pred = torch.argmax(roberta_model_output, dim=1)\n",
        "  roberta_model_pred = np.array(roberta_model_pred)\n",
        "  roberta_conf = torch.max(roberta_model_output, dim = 1)[0][0].item()\n",
        "\n",
        "  deberta_model_output = torch.softmax(deberta_model_output, dim = 1) * rel_freq_heuristic.cpu()\n",
        "  deberta_model_pred = torch.argmax(deberta_model_output, dim=1)\n",
        "  deberta_model_pred = np.array(deberta_model_pred)\n",
        "  deberta_conf = torch.max(deberta_model_output, dim = 1)[0][0].item()\n",
        "\n",
        "  if roberta_conf > deberta_conf:\n",
        "    final_output = roberta_model_pred\n",
        "  else:\n",
        "    final_output = deberta_model_pred\n",
        "\n",
        "  ground_truth_labels = np.array(ground_truth_labels.detach().cpu())\n",
        "\n",
        "  #checking how many values in model_output are equal to their corresponding values in ground_truth_labels\n",
        "  num_correct = np.sum(final_output == ground_truth_labels)\n",
        "  accuracy_val = num_correct / len(ground_truth_labels)\n",
        "  return accuracy_val"
      ],
      "metadata": {
        "id": "7UwXLMQzHq1j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_batches = []\n",
        "deberta_batches = []\n",
        "\n",
        "#unloading the dataloaders\n",
        "for batch in test_dataloader_roberta:\n",
        "  roberta_batches.append(batch)\n",
        "\n",
        "i = 0\n",
        "for batch in test_dataloader_deberta:\n",
        "  i+=1\n",
        "  for k in range(len(batch)):\n",
        "    temp_list = []\n",
        "    for j in range(4):      \n",
        "      if k >= len(batch[j]):\n",
        "        continue\n",
        "      temp_list.append(batch[j][k])\n",
        "    deberta_batches.append(temp_list)\n",
        "\n",
        "\n",
        "deberta_batches = deberta_batches[:-2]\n",
        "\n",
        "del test_dataloader_roberta, test_dataloader_deberta"
      ],
      "metadata": {
        "id": "I6JH3d3y_mS5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(roberta_batches))\n",
        "print(len(deberta_batches))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn-d7-tFAGh_",
        "outputId": "62498eb7-82fb-40f5-d2c4-a8f33915d44c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430\n",
            "430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loop\n",
        "roberta_model.eval()\n",
        "deberta_model.eval()\n",
        "\n",
        "total_test_acc = 0\n",
        "\n",
        "for index, (batch_roberta, batch_deberta) in enumerate(zip(roberta_batches, deberta_batches)):\n",
        "    input_ids_roberta, attention_mask_roberta, labels_roberta, rel_freq_heuristic_roberta = batch_roberta\n",
        "    input_ids_roberta, attention_mask_roberta, labels_roberta, rel_freq_heuristic_roberta = input_ids_roberta.to(device), attention_mask_roberta.to(device), labels_roberta.to(device), rel_freq_heuristic_roberta.to(device)\n",
        "\n",
        "    input_ids_deberta, attention_mask_deberta, labels_deberta, rel_freq_heuristic_deberta = batch_deberta\n",
        "    input_ids_deberta, attention_mask_deberta, labels_deberta, rel_freq_heuristic_deberta = input_ids_deberta.to(device), attention_mask_deberta.to(device), labels_deberta.to(device), rel_freq_heuristic_deberta.to(device)\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        roberta_outputs = roberta_model(input_ids_roberta, attention_mask = attention_mask_roberta, labels = labels_roberta)\n",
        "        roberta_output_data = roberta_outputs[1].detach().cpu()\n",
        "\n",
        "        deberta_outputs = deberta_model(input_ids_deberta.unsqueeze(0), attention_mask = attention_mask_deberta.unsqueeze(0), labels = labels_roberta)\n",
        "        deberta_output_data = deberta_outputs[1].detach().cpu()\n",
        "\n",
        "        #calculating accuracy for batch\n",
        "        total_test_acc += accuracy(roberta_output_data, deberta_output_data, labels_roberta, rel_freq_heuristic_roberta)\n",
        "    \n",
        "    # Delete unnecessary values to save memory\n",
        "    del input_ids_roberta, attention_mask_roberta, labels_roberta, rel_freq_heuristic_roberta, input_ids_deberta, attention_mask_deberta, labels_deberta, rel_freq_heuristic_deberta, roberta_outputs, deberta_outputs\n",
        "\n",
        "#Calculate average test accuracy\n",
        "avg_test_acc = total_test_acc / len(roberta_batches)\n",
        "print(f\"Test Accuracy: {avg_test_acc}\")"
      ],
      "metadata": {
        "id": "y4TwTn0wC2S0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b410951-75e2-4b44-93ed-65877fbe2a66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.79176749495809666\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}